{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from __future__ import annotations\r\n",
    "\r\n",
    "import tempfile\r\n",
    "from pathlib import Path\r\n",
    "from dataclasses import dataclass\r\n",
    "from typing import Optional\r\n",
    "\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import xarray as xr\r\n",
    "import pygmt\r\n",
    "from pygmt.clib import Session\r\n",
    "\r\n",
    "\r\n",
    "# ==========================\r\n",
    "# 配置\r\n",
    "# ==========================\r\n",
    "@dataclass\r\n",
    "class Config:\r\n",
    "    # 目标区 (W,E,S,N)\r\n",
    "    target_region: tuple[float, float, float, float] = (111.0, 117.0, 14.5, 18.5)\r\n",
    "\r\n",
    "    # 外扩度数\r\n",
    "    buffer_deg_lon: float = 5.0\r\n",
    "    buffer_deg_lat: float = 5.0\r\n",
    "\r\n",
    "    # 密度（kg/m^3）\r\n",
    "    rho_water: float = 1030.0\r\n",
    "    rho_crust: float = 2800.0\r\n",
    "\r\n",
    "    # Parker/gravfft 参数\r\n",
    "    nterms: int = 8\r\n",
    "    taper_percent: int = 15\r\n",
    "    extension_mode: str = \"m\"  # e/m/n\r\n",
    "    fft_mode: str = \"a\"\r\n",
    "    detrend_mode: Optional[str] = None  # 推荐用 \"a\"（去均值）或 \"l\"（不去）\r\n",
    "    field_opt: str = \"f+s\"  # 关键：-Ff+s（去均值时加回 slab） :contentReference[oaicite:5]{index=5}\r\n",
    "\r\n",
    "    # 本地小窗文件（不覆盖外扩区则自动下载远程网格）\r\n",
    "    faa_file: Path = Path(r\"E:\\wjy\\Gravity\\SCS_Gravity\\data\\Download_Data\\faa_01m_111E-117E_14.5N-18.5N.nc\")\r\n",
    "    bathy_file: Path = Path(r\"E:\\wjy\\Gravity\\SCS_Gravity\\data\\Download_Data\\gebco_01m_111E-117E_14.5N-18.5N.nc\")\r\n",
    "\r\n",
    "    out_dir: Path = Path(r\"E:\\wjy\\Gravity\\SCS_Gravity\\out\\Outdata\\CBA_expand_crop\")\r\n",
    "\r\n",
    "    # 自动下载 GMT 远程数据集\r\n",
    "    auto_fetch_if_needed: bool = True\r\n",
    "    fetch_resolution: str = \"01m\"  # @earth_faa_01m / @earth_relief_01m\r\n",
    "\r\n",
    "    # 不强制 _g/_p，而是“偏好 + 自动回退”\r\n",
    "    fetch_reg_preference: str = \"g\"\r\n",
    "    force_match_to_faa: bool = True\r\n",
    "\r\n",
    "    # 是否保留 gravfft 临时目录\r\n",
    "    keep_temp_dir: bool = True\r\n",
    "\r\n",
    "    # NaN 填补 & QC 参数\r\n",
    "    max_nan_frac_allowed: float = 0.02\r\n",
    "    ocean_negative_frac_warn: float = 0.50\r\n",
    "    ocean_negative_frac_flip: float = 0.30\r\n",
    "\r\n",
    "    # 画图参数\r\n",
    "    map_proj: str = \"M12c\"\r\n",
    "    cmap: str = \"turbo\"\r\n",
    "    dpi: int = 300\r\n",
    "\r\n",
    "    # GMT verbose: q(quiet)/n(normal)/v(verbose)\r\n",
    "    gmt_verbose_level: str = \"n\"\r\n",
    "\r\n",
    "\r\n",
    "# ==========================\r\n",
    "# 工具函数\r\n",
    "# ==========================\r\n",
    "def _guess_grid_var(ds: xr.Dataset, preferred: list[str] | None = None) -> str:\r\n",
    "    if preferred is None:\r\n",
    "        preferred = []\r\n",
    "    for name in preferred:\r\n",
    "        if name in ds.data_vars:\r\n",
    "            return name\r\n",
    "    for vname, da in ds.data_vars.items():\r\n",
    "        if da.ndim == 2:\r\n",
    "            return vname\r\n",
    "    raise ValueError(f\"No 2D grid found. data_vars={list(ds.data_vars)}\")\r\n",
    "\r\n",
    "\r\n",
    "def _standardize_lonlat_da(da: xr.DataArray) -> xr.DataArray:\r\n",
    "    if \"lon\" not in da.coords and \"x\" in da.coords:\r\n",
    "        da = da.rename({\"x\": \"lon\"})\r\n",
    "    if \"lat\" not in da.coords and \"y\" in da.coords:\r\n",
    "        da = da.rename({\"y\": \"lat\"})\r\n",
    "    if \"lon\" not in da.coords or \"lat\" not in da.coords:\r\n",
    "        raise ValueError(f\"Grid missing lon/lat coords, coords={list(da.coords)}\")\r\n",
    "\r\n",
    "    if np.any(np.diff(da[\"lon\"].values) < 0):\r\n",
    "        da = da.sortby(\"lon\")\r\n",
    "    if np.any(np.diff(da[\"lat\"].values) < 0):\r\n",
    "        da = da.sortby(\"lat\")\r\n",
    "    return da\r\n",
    "\r\n",
    "\r\n",
    "def _subset_region_da(da: xr.DataArray, region: tuple[float, float, float, float]) -> xr.DataArray:\r\n",
    "    w, e, s, n = region\r\n",
    "    da = _standardize_lonlat_da(da)\r\n",
    "    return da.sel(lon=slice(w, e), lat=slice(s, n))\r\n",
    "\r\n",
    "\r\n",
    "def _expand_region(region: tuple[float, float, float, float], dlon: float, dlat: float) -> tuple[float, float, float, float]:\r\n",
    "    w, e, s, n = region\r\n",
    "    return (w - dlon, e + dlon, s - dlat, n + dlat)\r\n",
    "\r\n",
    "\r\n",
    "def _grid_step_deg(coord: xr.DataArray) -> float:\r\n",
    "    v = np.asarray(coord.values, dtype=float)\r\n",
    "    dv = np.diff(v)\r\n",
    "    dv = dv[np.isfinite(dv)]\r\n",
    "    if dv.size == 0:\r\n",
    "        raise ValueError(\"Cannot determine grid step (empty diffs).\")\r\n",
    "    return float(np.median(np.abs(dv)))\r\n",
    "\r\n",
    "\r\n",
    "def _coverage_ok(da: xr.DataArray, region: tuple[float, float, float, float], tol_cells: float = 0.55) -> bool:\r\n",
    "    w, e, s, n = region\r\n",
    "    da = _standardize_lonlat_da(da)\r\n",
    "\r\n",
    "    lon_min = float(da.lon.min())\r\n",
    "    lon_max = float(da.lon.max())\r\n",
    "    lat_min = float(da.lat.min())\r\n",
    "    lat_max = float(da.lat.max())\r\n",
    "\r\n",
    "    dx = _grid_step_deg(da.lon)\r\n",
    "    dy = _grid_step_deg(da.lat)\r\n",
    "    tol_lon = tol_cells * dx\r\n",
    "    tol_lat = tol_cells * dy\r\n",
    "\r\n",
    "    ok = (lon_min <= w + tol_lon) and (lon_max >= e - tol_lon) and (lat_min <= s + tol_lat) and (lat_max >= n - tol_lat)\r\n",
    "\r\n",
    "    print(\r\n",
    "        f\"[QC] coverage lon[{lon_min:.6f},{lon_max:.6f}] lat[{lat_min:.6f},{lat_max:.6f}] \"\r\n",
    "        f\"dx={dx:.6f} dy={dy:.6f} tol_lon={tol_lon:.6f} tol_lat={tol_lat:.6f}  want={region}  ok={ok}\"\r\n",
    "    )\r\n",
    "    return ok\r\n",
    "\r\n",
    "\r\n",
    "def _require_nan_frac_below(name: str, da: xr.DataArray, max_nan_frac: float) -> None:\r\n",
    "    v = da.values\r\n",
    "    frac = np.isnan(v).sum() / v.size\r\n",
    "    print(f\"[QC] {name}: NaN fraction = {frac:.3%}\")\r\n",
    "    if frac > max_nan_frac:\r\n",
    "        raise ValueError(f\"{name}: NaN fraction too high ({frac:.3%} > {max_nan_frac:.3%}).\")\r\n",
    "\r\n",
    "\r\n",
    "def _fill_nans_2d(da: xr.DataArray, name: str, prefer_nearest: bool = False) -> xr.DataArray:\r\n",
    "    da = _standardize_lonlat_da(da)\r\n",
    "    if not np.isnan(da.values).any():\r\n",
    "        return da\r\n",
    "\r\n",
    "    print(f\"[INFO] Filling NaNs for {name} ... prefer_nearest={prefer_nearest}\")\r\n",
    "    out = da\r\n",
    "\r\n",
    "    if prefer_nearest:\r\n",
    "        out = out.interpolate_na(dim=\"lon\", method=\"nearest\", fill_value=\"extrapolate\")\r\n",
    "        out = out.interpolate_na(dim=\"lat\", method=\"nearest\", fill_value=\"extrapolate\")\r\n",
    "        if np.isnan(out.values).any():\r\n",
    "            out = out.interpolate_na(dim=\"lon\", method=\"linear\", fill_value=\"extrapolate\")\r\n",
    "            out = out.interpolate_na(dim=\"lat\", method=\"linear\", fill_value=\"extrapolate\")\r\n",
    "    else:\r\n",
    "        out = out.interpolate_na(dim=\"lon\", method=\"linear\", fill_value=\"extrapolate\")\r\n",
    "        out = out.interpolate_na(dim=\"lat\", method=\"linear\", fill_value=\"extrapolate\")\r\n",
    "        if np.isnan(out.values).any():\r\n",
    "            out = out.interpolate_na(dim=\"lon\", method=\"nearest\", fill_value=\"extrapolate\")\r\n",
    "            out = out.interpolate_na(dim=\"lat\", method=\"nearest\", fill_value=\"extrapolate\")\r\n",
    "\r\n",
    "    if np.isnan(out.values).any():\r\n",
    "        nleft = int(np.isnan(out.values).sum())\r\n",
    "        print(f\"[WARN] {name}: still has {nleft} NaNs after interpolation; fill with 0.\")\r\n",
    "        out = out.fillna(0.0)\r\n",
    "\r\n",
    "    return out\r\n",
    "\r\n",
    "\r\n",
    "def _qc_stats(name: str, da: xr.DataArray) -> None:\r\n",
    "    v = da.values\r\n",
    "    print(\r\n",
    "        f\"[QC] {name}: min={float(np.nanmin(v)):.3f} \"\r\n",
    "        f\"max={float(np.nanmax(v)):.3f} mean={float(np.nanmean(v)):.3f} std={float(np.nanstd(v)):.3f}\"\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "def _fix_bathy_sign_if_needed(bathy: xr.DataArray, cfg: Config) -> xr.DataArray:\r\n",
    "    bathy = _standardize_lonlat_da(bathy)\r\n",
    "    neg_frac = float((bathy < 0).sum() / bathy.size)\r\n",
    "    _qc_stats(\"Bathy(before sign check)\", bathy)\r\n",
    "    print(f\"[QC] bathy<0 fraction = {neg_frac:.3f}\")\r\n",
    "\r\n",
    "    if neg_frac < cfg.ocean_negative_frac_warn:\r\n",
    "        print(f\"[WARN] bathy<0 fraction is low (<{cfg.ocean_negative_frac_warn}). Check if bathy sign is correct.\")\r\n",
    "\r\n",
    "    if neg_frac < cfg.ocean_negative_frac_flip:\r\n",
    "        vmin = float(np.nanmin(bathy.values))\r\n",
    "        vmax = float(np.nanmax(bathy.values))\r\n",
    "        if vmin > -1e-3 and vmax > 0:\r\n",
    "            print(\"[WARN] Bathy seems depth-positive. Flipping sign: elevation = -depth.\")\r\n",
    "            bathy = -bathy\r\n",
    "            _qc_stats(\"Bathy(after flip)\", bathy)\r\n",
    "    return bathy\r\n",
    "\r\n",
    "\r\n",
    "def _to_tmp_grid(da: xr.DataArray, outpath: Path) -> None:\r\n",
    "    da2 = _standardize_lonlat_da(da.astype(np.float32))\r\n",
    "    ds = da2.to_dataset(name=\"z\").rename({\"lon\": \"x\", \"lat\": \"y\"})\r\n",
    "    ds.to_netcdf(outpath, engine=\"scipy\")\r\n",
    "\r\n",
    "\r\n",
    "def _read_grid(path: Path) -> xr.DataArray:\r\n",
    "    ds = xr.open_dataset(path)\r\n",
    "    vname = _guess_grid_var(ds, preferred=[\"z\"])\r\n",
    "    da = ds[vname]\r\n",
    "    ds.close()\r\n",
    "    return _standardize_lonlat_da(da)\r\n",
    "\r\n",
    "\r\n",
    "def _coerce_grid_like(src: xr.DataArray, tmpl: xr.DataArray) -> xr.DataArray:\r\n",
    "    src = _standardize_lonlat_da(src)\r\n",
    "    tmpl = _standardize_lonlat_da(tmpl)\r\n",
    "    same_shape = (src.sizes[\"lon\"] == tmpl.sizes[\"lon\"]) and (src.sizes[\"lat\"] == tmpl.sizes[\"lat\"])\r\n",
    "    if same_shape:\r\n",
    "        return src.assign_coords(lon=tmpl[\"lon\"].values, lat=tmpl[\"lat\"].values)\r\n",
    "    return src.interp(lon=tmpl[\"lon\"], lat=tmpl[\"lat\"], method=\"linear\")\r\n",
    "\r\n",
    "\r\n",
    "def _snap_or_interp_like(da: xr.DataArray, tmpl: xr.DataArray, name: str) -> xr.DataArray:\r\n",
    "    da = _standardize_lonlat_da(da)\r\n",
    "    tmpl = _standardize_lonlat_da(tmpl)\r\n",
    "\r\n",
    "    lon_ok = (da.sizes[\"lon\"] == tmpl.sizes[\"lon\"]) and np.allclose(da.lon.values, tmpl.lon.values, atol=1e-10, rtol=0)\r\n",
    "    lat_ok = (da.sizes[\"lat\"] == tmpl.sizes[\"lat\"]) and np.allclose(da.lat.values, tmpl.lat.values, atol=1e-10, rtol=0)\r\n",
    "\r\n",
    "    if lon_ok and lat_ok:\r\n",
    "        print(f\"[QC] {name}: coords match template; skip interpolation.\")\r\n",
    "        return da.assign_coords(lon=tmpl.lon.values, lat=tmpl.lat.values)\r\n",
    "\r\n",
    "    print(f\"[QC] {name}: coords differ; do linear interpolation.\")\r\n",
    "    return da.interp(lon=tmpl.lon, lat=tmpl.lat, method=\"linear\")\r\n",
    "\r\n",
    "\r\n",
    "def _fit_plane_slope_km(da: xr.DataArray) -> tuple[float, float, float]:\r\n",
    "    da = _standardize_lonlat_da(da)\r\n",
    "    lon = da.lon.values\r\n",
    "    lat = da.lat.values\r\n",
    "    Lon, Lat = np.meshgrid(lon, lat)\r\n",
    "\r\n",
    "    lat0 = np.deg2rad(float(np.nanmean(Lat)))\r\n",
    "    x = (Lon - np.nanmean(Lon)) * 111.32 * np.cos(lat0)\r\n",
    "    y = (Lat - np.nanmean(Lat)) * 110.57\r\n",
    "\r\n",
    "    z = da.values\r\n",
    "    m = np.isfinite(z)\r\n",
    "    A = np.c_[x[m], y[m], np.ones(m.sum())]\r\n",
    "    coef, *_ = np.linalg.lstsq(A, z[m], rcond=None)\r\n",
    "    a, b, c = coef\r\n",
    "    return float(a), float(b), float(c)\r\n",
    "\r\n",
    "\r\n",
    "# ==========================\r\n",
    "# GMT wrappers\r\n",
    "# ==========================\r\n",
    "def gmt_gravfft(\r\n",
    "    ingrid_nc: Path,\r\n",
    "    outgrid_nc: Path,\r\n",
    "    drho: float,\r\n",
    "    nterms: int,\r\n",
    "    taper_percent: int = 15,\r\n",
    "    extension_mode: str = \"m\",\r\n",
    "    fft_mode: str = \"a\",\r\n",
    "    detrend_mode: Optional[str] = None,\r\n",
    "    field_opt: str = \"f+s\",  # 新增：-F 选项\r\n",
    "    gmt_verbose_level: str = \"n\",\r\n",
    "    verbose: bool = True,\r\n",
    ") -> None:\r\n",
    "    if extension_mode not in (\"e\", \"m\", \"n\"):\r\n",
    "        raise ValueError(\"extension_mode must be one of 'e','m','n'\")\r\n",
    "    if fft_mode not in (\"a\", \"f\", \"m\", \"r\", \"s\"):\r\n",
    "        raise ValueError(\"fft_mode must be one of 'a','f','m','r','s'\")\r\n",
    "    if detrend_mode is not None and detrend_mode not in (\"a\", \"d\", \"h\", \"l\"):\r\n",
    "        raise ValueError(\"detrend_mode must be one of 'a','d','h','l', or None\")\r\n",
    "    if not (0 <= taper_percent <= 100):\r\n",
    "        raise ValueError(\"taper_percent must be in [0,100]\")\r\n",
    "    if not (1 <= nterms <= 10):\r\n",
    "        raise ValueError(\"nterms must be in [1,10]\")\r\n",
    "    if gmt_verbose_level not in (\"q\", \"n\", \"v\"):\r\n",
    "        raise ValueError(\"gmt_verbose_level must be one of 'q','n','v'\")\r\n",
    "\r\n",
    "    Nopt = f\"-N{fft_mode}+{extension_mode}+t{taper_percent}+v\"\r\n",
    "    if detrend_mode is not None:\r\n",
    "        Nopt = f\"-N{fft_mode}+{detrend_mode}+{extension_mode}+t{taper_percent}+v\"\r\n",
    "\r\n",
    "    cmd_parts = [\r\n",
    "        ingrid_nc.as_posix(),\r\n",
    "        f\"-D{drho}\",\r\n",
    "        f\"-G{outgrid_nc.as_posix()}\",\r\n",
    "        f\"-E{nterms}\",\r\n",
    "        f\"-F{field_opt}\",  # 关键：-Ff+s :contentReference[oaicite:6]{index=6}\r\n",
    "        Nopt,\r\n",
    "        \"-fg\",\r\n",
    "        f\"-V{gmt_verbose_level}\",\r\n",
    "    ]\r\n",
    "    cmd = \" \".join(cmd_parts)\r\n",
    "\r\n",
    "    if verbose:\r\n",
    "        print(\"[GMT] gravfft\", cmd)\r\n",
    "\r\n",
    "    with Session() as ses:\r\n",
    "        ses.call_module(\"gravfft\", cmd)\r\n",
    "\r\n",
    "    if not outgrid_nc.exists():\r\n",
    "        raise FileNotFoundError(f\"gravfft did not create output grid: {outgrid_nc}\")\r\n",
    "\r\n",
    "\r\n",
    "def _grdcut_remote(dataset: str, region: tuple[float, float, float, float], out_nc: Path) -> None:\r\n",
    "    w, e, s, n = region\r\n",
    "    out_nc.parent.mkdir(parents=True, exist_ok=True)\r\n",
    "    pygmt.grdcut(grid=dataset, region=[w, e, s, n], outgrid=out_nc.as_posix(), verbose=\"q\")\r\n",
    "    if not out_nc.exists():\r\n",
    "        raise FileNotFoundError(f\"grdcut did not create output: {out_nc}\")\r\n",
    "\r\n",
    "\r\n",
    "def _grdcut_remote_with_fallback(\r\n",
    "    base: str,\r\n",
    "    res: str,\r\n",
    "    reg_pref: str,\r\n",
    "    region: tuple[float, float, float, float],\r\n",
    "    out_nc: Path,\r\n",
    ") -> str:\r\n",
    "    candidates = [f\"@{base}_{res}_{reg_pref}\", f\"@{base}_{res}\"]\r\n",
    "    if reg_pref == \"g\":\r\n",
    "        candidates.append(f\"@{base}_{res}_p\")\r\n",
    "    elif reg_pref == \"p\":\r\n",
    "        candidates.append(f\"@{base}_{res}_g\")\r\n",
    "\r\n",
    "    last_err = None\r\n",
    "    for dsname in candidates:\r\n",
    "        try:\r\n",
    "            print(f\"[INFO] Trying remote dataset: {dsname}\")\r\n",
    "            _grdcut_remote(dsname, region, out_nc)\r\n",
    "            print(f\"[INFO] Success: {dsname}\")\r\n",
    "            return dsname\r\n",
    "        except Exception as e:\r\n",
    "            last_err = e\r\n",
    "            print(f\"[WARN] Failed: {dsname}  ({type(e).__name__}: {e})\")\r\n",
    "\r\n",
    "    raise RuntimeError(f\"All remote dataset candidates failed for {base}_{res}. Last error: {last_err}\")\r\n",
    "\r\n",
    "\r\n",
    "def _load_local_grid(path: Path, preferred_vars: list[str]) -> xr.DataArray:\r\n",
    "    ds = xr.open_dataset(path)\r\n",
    "    vname = _guess_grid_var(ds, preferred=preferred_vars)\r\n",
    "    da = ds[vname]\r\n",
    "    ds.close()\r\n",
    "    return _standardize_lonlat_da(da)\r\n",
    "\r\n",
    "\r\n",
    "def _resample_grid_to_template_file(\r\n",
    "    src_grid_nc: Path,\r\n",
    "    tmpl: xr.DataArray,\r\n",
    "    out_nc: Path,\r\n",
    "    registration: str,\r\n",
    ") -> None:\r\n",
    "    tmpl = _standardize_lonlat_da(tmpl)\r\n",
    "    dx = _grid_step_deg(tmpl.lon)\r\n",
    "    dy = _grid_step_deg(tmpl.lat)\r\n",
    "    region = [float(tmpl.lon.min()), float(tmpl.lon.max()), float(tmpl.lat.min()), float(tmpl.lat.max())]\r\n",
    "\r\n",
    "    out_nc.parent.mkdir(parents=True, exist_ok=True)\r\n",
    "    print(f\"[INFO] grdsample -> match template: {src_grid_nc.name} -> {out_nc.name}  reg={registration} dx={dx} dy={dy}\")\r\n",
    "    pygmt.grdsample(\r\n",
    "        grid=str(src_grid_nc),\r\n",
    "        outgrid=str(out_nc),\r\n",
    "        region=region,\r\n",
    "        spacing=[dx, dy],\r\n",
    "        registration=registration,\r\n",
    "        interpolation=\"b\",\r\n",
    "        verbose=\"q\",\r\n",
    "    )\r\n",
    "    if not out_nc.exists():\r\n",
    "        raise FileNotFoundError(f\"grdsample did not create output: {out_nc}\")\r\n",
    "\r\n",
    "\r\n",
    "def _load_faa_and_bathy_covering_region(cfg: Config, region_exp: tuple[float, float, float, float]) -> tuple[xr.DataArray, xr.DataArray]:\r\n",
    "    faa0 = _load_local_grid(cfg.faa_file, [\"faa\", \"FAA\", \"free_air\", \"faa_mgal\", \"z\"])\r\n",
    "    bathy0 = _load_local_grid(cfg.bathy_file, [\"elevation\", \"z\", \"gebco\", \"topo\", \"bathy\"])\r\n",
    "\r\n",
    "    if _coverage_ok(faa0, region_exp) and _coverage_ok(bathy0, region_exp):\r\n",
    "        return faa0, bathy0\r\n",
    "\r\n",
    "    if not cfg.auto_fetch_if_needed:\r\n",
    "        raise ValueError(\"Local grids do not cover expanded region and auto_fetch_if_needed=False.\")\r\n",
    "\r\n",
    "    print(\"[INFO] Local grids too small. Fetching expanded grids via GMT remote datasets...\")\r\n",
    "    res = cfg.fetch_resolution\r\n",
    "    pref = cfg.fetch_reg_preference\r\n",
    "\r\n",
    "    faa_nc = cfg.out_dir / f\"faa_{res}_expanded_{region_exp[0]:.1f}_{region_exp[1]:.1f}_{region_exp[2]:.1f}_{region_exp[3]:.1f}.nc\"\r\n",
    "    faa_ds_used = _grdcut_remote_with_fallback(\"earth_faa\", res, pref, region_exp, faa_nc)\r\n",
    "\r\n",
    "    rel_nc = cfg.out_dir / f\"relief_{res}_expanded_{region_exp[0]:.1f}_{region_exp[1]:.1f}_{region_exp[2]:.1f}_{region_exp[3]:.1f}.nc\"\r\n",
    "    rel_ds_used = _grdcut_remote_with_fallback(\"earth_relief\", res, pref, region_exp, rel_nc)\r\n",
    "\r\n",
    "    faa1 = _load_local_grid(faa_nc, [\"z\", \"faa\", \"FAA\"])\r\n",
    "    bathy1 = _load_local_grid(rel_nc, [\"z\", \"elevation\", \"topo\", \"bathy\"])\r\n",
    "\r\n",
    "    print(f\"[INFO] FAA dataset used: {faa_ds_used}\")\r\n",
    "    print(f\"[INFO] Relief dataset used: {rel_ds_used}\")\r\n",
    "\r\n",
    "    if cfg.force_match_to_faa:\r\n",
    "        dx = _grid_step_deg(faa1.lon)\r\n",
    "        frac = (float(faa1.lon.min()) / dx) - np.floor(float(faa1.lon.min()) / dx)\r\n",
    "        reg = \"p\" if abs(frac - 0.5) < 1e-2 else \"g\"\r\n",
    "        rel_rs_nc = cfg.out_dir / f\"relief_{res}_expanded_MATCHFAA_{reg}.nc\"\r\n",
    "        _resample_grid_to_template_file(rel_nc, faa1, rel_rs_nc, registration=reg)\r\n",
    "        bathy1 = _load_local_grid(rel_rs_nc, [\"z\", \"elevation\", \"topo\", \"bathy\"])\r\n",
    "\r\n",
    "    return faa1, bathy1\r\n",
    "\r\n",
    "\r\n",
    "def compute_cba_expand_then_crop(cfg: Config) -> dict[str, xr.DataArray]:\r\n",
    "    region_exp = _expand_region(cfg.target_region, cfg.buffer_deg_lon, cfg.buffer_deg_lat)\r\n",
    "    print(\"Target region:\", cfg.target_region)\r\n",
    "    print(\"Expanded region:\", region_exp)\r\n",
    "\r\n",
    "    faa0, bathy0 = _load_faa_and_bathy_covering_region(cfg, region_exp)\r\n",
    "\r\n",
    "    faa_exp = _subset_region_da(faa0, region_exp)\r\n",
    "    bathy_exp = _subset_region_da(bathy0, region_exp)\r\n",
    "\r\n",
    "    _require_nan_frac_below(\"FAA(expanded)\", faa_exp, cfg.max_nan_frac_allowed)\r\n",
    "    _require_nan_frac_below(\"Bathy(expanded)\", bathy_exp, cfg.max_nan_frac_allowed)\r\n",
    "\r\n",
    "    faa_exp = _fill_nans_2d(faa_exp, \"FAA(expanded)\", prefer_nearest=False)\r\n",
    "    bathy_exp = _fill_nans_2d(bathy_exp, \"Bathy(expanded)\", prefer_nearest=True)\r\n",
    "    bathy_exp = _fix_bathy_sign_if_needed(bathy_exp, cfg)\r\n",
    "\r\n",
    "    h_ocean = bathy_exp.where(bathy_exp < 0.0, 0.0)\r\n",
    "    h_land = bathy_exp.where(bathy_exp > 0.0, 0.0)\r\n",
    "\r\n",
    "    drho_wc = cfg.rho_crust - cfg.rho_water\r\n",
    "    drho_topo = cfg.rho_crust - 0.0\r\n",
    "\r\n",
    "    td = Path(tempfile.mkdtemp(prefix=\"cba_gravfft_\"))\r\n",
    "    print(\"[INFO] Using temp dir:\", td)\r\n",
    "\r\n",
    "    ocean_nc_in = td / \"h_ocean.nc\"\r\n",
    "    land_nc_in = td / \"h_land.nc\"\r\n",
    "    _to_tmp_grid(h_ocean, ocean_nc_in)\r\n",
    "    _to_tmp_grid(h_land, land_nc_in)\r\n",
    "\r\n",
    "    g_wc_nc = td / \"g_wc.nc\"\r\n",
    "    g_topo_nc = td / \"g_topo.nc\"\r\n",
    "\r\n",
    "    gmt_gravfft(\r\n",
    "        ocean_nc_in, g_wc_nc, drho_wc, cfg.nterms,\r\n",
    "        taper_percent=cfg.taper_percent,\r\n",
    "        extension_mode=cfg.extension_mode,\r\n",
    "        fft_mode=cfg.fft_mode,\r\n",
    "        detrend_mode=cfg.detrend_mode,\r\n",
    "        field_opt=cfg.field_opt,\r\n",
    "        gmt_verbose_level=cfg.gmt_verbose_level,\r\n",
    "    )\r\n",
    "    gmt_gravfft(\r\n",
    "        land_nc_in, g_topo_nc, drho_topo, cfg.nterms,\r\n",
    "        taper_percent=cfg.taper_percent,\r\n",
    "        extension_mode=cfg.extension_mode,\r\n",
    "        fft_mode=cfg.fft_mode,\r\n",
    "        detrend_mode=cfg.detrend_mode,\r\n",
    "        field_opt=cfg.field_opt,\r\n",
    "        gmt_verbose_level=cfg.gmt_verbose_level,\r\n",
    "    )\r\n",
    "\r\n",
    "    g_wc = _read_grid(g_wc_nc)\r\n",
    "    g_topo = _read_grid(g_topo_nc)\r\n",
    "\r\n",
    "    g_wc = _coerce_grid_like(g_wc, faa_exp)\r\n",
    "    g_topo = _coerce_grid_like(g_topo, faa_exp)\r\n",
    "    faa_exp, g_wc, g_topo = xr.align(faa_exp, g_wc, g_topo, join=\"override\")\r\n",
    "\r\n",
    "    _qc_stats(\"FAA(exp)\", faa_exp)\r\n",
    "    _qc_stats(\"g_wc(exp)\", g_wc)\r\n",
    "    _qc_stats(\"g_topo(exp)\", g_topo)\r\n",
    "\r\n",
    "    cba_exp = faa_exp - (g_wc + g_topo)\r\n",
    "    cba_exp.name = \"CBA_raw\"\r\n",
    "    _qc_stats(\"CBA_raw(exp)\", cba_exp)\r\n",
    "\r\n",
    "    w, e, s, n = cfg.target_region\r\n",
    "    cba_tgt = cba_exp.sel(lon=slice(w, e), lat=slice(s, n))\r\n",
    "    g_wc_tgt = g_wc.sel(lon=slice(w, e), lat=slice(s, n))\r\n",
    "    g_topo_tgt = g_topo.sel(lon=slice(w, e), lat=slice(s, n))\r\n",
    "    faa_tgt = faa_exp.sel(lon=slice(w, e), lat=slice(s, n))\r\n",
    "\r\n",
    "    tmpl0 = _load_local_grid(cfg.faa_file, [\"faa\", \"FAA\", \"free_air\", \"faa_mgal\", \"z\"])\r\n",
    "    tmpl = _subset_region_da(tmpl0, cfg.target_region)\r\n",
    "\r\n",
    "    cba_tgt = _snap_or_interp_like(cba_tgt, tmpl, \"CBA_raw(tgt)\")\r\n",
    "    g_wc_tgt = _snap_or_interp_like(g_wc_tgt, tmpl, \"g_wc(tgt)\")\r\n",
    "    g_topo_tgt = _snap_or_interp_like(g_topo_tgt, tmpl, \"g_topo(tgt)\")\r\n",
    "    faa_tgt = _snap_or_interp_like(faa_tgt, tmpl, \"FAA(tgt)\")\r\n",
    "\r\n",
    "    def _print_plane(name: str, da: xr.DataArray) -> None:\r\n",
    "        a, b, _ = _fit_plane_slope_km(da)\r\n",
    "        print(f\"[QC] {name} plane slope: a={a:.4f} mGal/km (E-W), b={b:.4f} mGal/km (N-S)\")\r\n",
    "\r\n",
    "    _print_plane(\"FAA(tgt)\", faa_tgt)\r\n",
    "    _print_plane(\"g_wc(tgt)\", g_wc_tgt)\r\n",
    "    _print_plane(\"g_topo(tgt)\", g_topo_tgt)\r\n",
    "    _print_plane(\"g_wc+g_topo(tgt)\", (g_wc_tgt + g_topo_tgt))\r\n",
    "    _print_plane(\"CBA_raw(tgt)\", cba_tgt)\r\n",
    "\r\n",
    "    cfg.out_dir.mkdir(parents=True, exist_ok=True)\r\n",
    "    out_nc = cfg.out_dir / f\"CBA_raw_expand{cfg.buffer_deg_lon:.1f}deg_{cfg.buffer_deg_lat:.1f}deg.nc\"\r\n",
    "    xr.Dataset(\r\n",
    "        data_vars=dict(\r\n",
    "            FAA=faa_tgt.astype(\"float32\"),\r\n",
    "            g_wc=g_wc_tgt.astype(\"float32\"),\r\n",
    "            g_topo=g_topo_tgt.astype(\"float32\"),\r\n",
    "            CBA_raw=cba_tgt.astype(\"float32\"),\r\n",
    "        ),\r\n",
    "        coords=dict(lon=cba_tgt.lon, lat=cba_tgt.lat),\r\n",
    "    ).to_netcdf(out_nc)\r\n",
    "    print(\"Saved:\", out_nc)\r\n",
    "\r\n",
    "    return {\"CBA_raw\": cba_tgt, \"FAA\": faa_tgt, \"g_wc\": g_wc_tgt, \"g_topo\": g_topo_tgt}\r\n",
    "\r\n",
    "\r\n",
    "def quick_map_fullrange(da: xr.DataArray, title: str, out_png: Path, cfg: Config) -> None:\r\n",
    "    fig = pygmt.Figure()\r\n",
    "    region = [float(da.lon.min()), float(da.lon.max()), float(da.lat.min()), float(da.lat.max())]\r\n",
    "\r\n",
    "    da0 = da.load()\r\n",
    "    vmin0 = float(np.nanmin(da0.values))\r\n",
    "    vmax0 = float(np.nanmax(da0.values))\r\n",
    "    series = [-max(abs(vmin0), abs(vmax0)), max(abs(vmin0), abs(vmax0))] if (vmin0 < 0 < vmax0) else [vmin0, vmax0]\r\n",
    "\r\n",
    "    pygmt.makecpt(cmap=cfg.cmap, series=series, background=True)\r\n",
    "    fig.grdimage(da0, region=region, projection=cfg.map_proj, frame=[\"a\", f\"+t{title}\"], cmap=True)\r\n",
    "    fig.coast(region=region, projection=cfg.map_proj, shorelines=\"0.8p,black\", borders=\"1/0.5p,black\")\r\n",
    "    fig.colorbar(frame='af+l\"mGal\"')\r\n",
    "    fig.savefig(out_png, dpi=cfg.dpi)\r\n",
    "    print(\"Saved:\", out_png)\r\n",
    "\r\n",
    "\r\n",
    "def main() -> None:\r\n",
    "    cfg = Config()\r\n",
    "\r\n",
    "    # 关键设置：用 +a 去均值，并用 -Ff+s 加回 slab，避免默认 +h(mid-value) 造成的大基线漂移 :contentReference[oaicite:7]{index=7}\r\n",
    "    cfg.detrend_mode = \"a\"\r\n",
    "    cfg.field_opt = \"f+s\"\r\n",
    "\r\n",
    "    cfg.out_dir.mkdir(parents=True, exist_ok=True)\r\n",
    "    print(cfg)\r\n",
    "\r\n",
    "    res = compute_cba_expand_then_crop(cfg)\r\n",
    "\r\n",
    "    da = res[\"CBA_raw\"].load()\r\n",
    "    print(\"[QC] CBA_raw(tgt) stats:\",\r\n",
    "          float(np.nanmin(da)), float(np.nanmax(da)), float(np.nanmean(da)), float(np.nanstd(da)))\r\n",
    "\r\n",
    "    out_png = cfg.out_dir / \"QC_CBA_fullrange.png\"\r\n",
    "    quick_map_fullrange(res[\"CBA_raw\"], \"CBA_raw (expanded->crop)\", out_png, cfg)\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    main()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Config(target_region=(111.0, 117.0, 14.5, 18.5), buffer_deg_lon=5.0, buffer_deg_lat=5.0, rho_water=1030.0, rho_crust=2800.0, nterms=8, taper_percent=15, extension_mode='m', fft_mode='a', detrend_mode=None, faa_file=WindowsPath('E:/wjy/Gravity/SCS_Gravity/data/Download_Data/faa_01m_111E-117E_14.5N-18.5N.nc'), bathy_file=WindowsPath('E:/wjy/Gravity/SCS_Gravity/data/Download_Data/gebco_01m_111E-117E_14.5N-18.5N.nc'), out_dir=WindowsPath('E:/wjy/Gravity/SCS_Gravity/out/Outdata/CBA_expand_crop'), auto_fetch_if_needed=True, fetch_resolution='01m', fetch_reg_preference='g', force_match_to_faa=True, keep_temp_dir=True, max_nan_frac_allowed=0.02, ocean_negative_frac_warn=0.5, ocean_negative_frac_flip=0.3, map_proj='M12c', cmap='turbo', dpi=300, gmt_verbose_level='n')\n",
      "Target region: (111.0, 117.0, 14.5, 18.5)\n",
      "Expanded region: (106.0, 122.0, 9.5, 23.5)\n",
      "[QC] coverage lon[111.008333,116.991667] lat[14.508333,18.491667] dx=0.016667 dy=0.016667 tol_lon=0.009167 tol_lat=0.009167  want=(106.0, 122.0, 9.5, 23.5)  ok=False\n",
      "[QC] coverage lon[111.000000,117.000000] lat[14.500000,18.500000] dx=0.016667 dy=0.016667 tol_lon=0.009167 tol_lat=0.009167  want=(106.0, 122.0, 9.5, 23.5)  ok=False\n",
      "[INFO] Local grids too small. Fetching expanded grids via GMT remote datasets...\n",
      "[INFO] Trying remote dataset: @earth_faa_01m_g\n",
      "[WARN] Failed: @earth_faa_01m_g  (GMTCLibError: Module 'grdcut' failed with status code 72:\n",
      ")\n",
      "[INFO] Trying remote dataset: @earth_faa_01m\n",
      "[INFO] Success: @earth_faa_01m\n",
      "[INFO] Trying remote dataset: @earth_relief_01m_g\n",
      "[INFO] Success: @earth_relief_01m_g\n",
      "[INFO] FAA dataset used: @earth_faa_01m\n",
      "[INFO] Relief dataset used: @earth_relief_01m_g\n",
      "[QC] coverage lon[106.008333,121.991667] lat[9.508333,23.491667] dx=0.016667 dy=0.016667 tol_lon=0.009167 tol_lat=0.009167  want=(106.0, 122.0, 9.5, 23.5)  ok=True\n",
      "[QC] coverage lon[106.000000,122.000000] lat[9.500000,23.500000] dx=0.016667 dy=0.016667 tol_lon=0.009167 tol_lat=0.009167  want=(106.0, 122.0, 9.5, 23.5)  ok=True\n",
      "[INFO] grdsample -> match template: relief_01m_expanded_106.0_122.0_9.5_23.5.nc -> relief_01m_expanded_MATCHFAA_p.nc  reg=p dx=0.01666666666666572 dy=0.01666666666666572\n",
      "[QC] FAA(expanded): NaN fraction = 0.000%\n",
      "[QC] Bathy(expanded): NaN fraction = 0.000%\n",
      "[QC] Bathy(before sign check): min=-5208.194 max=3364.250 mean=-1350.967 std=1679.321\n",
      "[QC] bathy<0 fraction = 0.768\n",
      "[QC] h_ocean: NaN fraction = 0.000%\n",
      "[QC] h_land: NaN fraction = 0.000%\n",
      "[INFO] Using temp dir: C:\\Users\\user\\AppData\\Local\\Temp\\cba_gravfft_7l08b270\n",
      "[GMT] gravfft C:/Users/user/AppData/Local/Temp/cba_gravfft_7l08b270/h_ocean.nc -D1770.0 -GC:/Users/user/AppData/Local/Temp/cba_gravfft_7l08b270/g_wc.nc -E8 -Na+m+t15+v -fg -Vn\n",
      "[GMT] gravfft C:/Users/user/AppData/Local/Temp/cba_gravfft_7l08b270/h_land.nc -D2800.0 -GC:/Users/user/AppData/Local/Temp/cba_gravfft_7l08b270/g_topo.nc -E8 -Na+m+t15+v -fg -Vn\n",
      "[QC] FAA(exp): min=-209.325 max=334.525 mean=4.967 std=37.461\n",
      "[QC] g_wc(exp): min=-156.962 max=192.915 mean=87.743 std=116.900\n",
      "[QC] g_topo(exp): min=-197.359 max=165.061 mean=-189.005 std=22.458\n",
      "[QC] CBA_raw(exp): min=-124.248 max=354.486 mean=106.208 std=123.986\n",
      "[QC] CBA_raw(tgt): coords match template; skip interpolation.\n",
      "[QC] g_wc(tgt): coords match template; skip interpolation.\n",
      "[QC] g_topo(tgt): coords match template; skip interpolation.\n",
      "[QC] FAA(tgt): coords match template; skip interpolation.\n",
      "[QC] FAA(tgt) plane slope: a=0.0302 mGal/km (E-W), b=-0.0544 mGal/km (N-S)\n",
      "[QC] g_wc(tgt) plane slope: a=-0.3963 mGal/km (E-W), b=0.0596 mGal/km (N-S)\n",
      "[QC] g_topo(tgt) plane slope: a=-0.0001 mGal/km (E-W), b=0.0000 mGal/km (N-S)\n",
      "[QC] g_wc+g_topo(tgt) plane slope: a=-0.3964 mGal/km (E-W), b=0.0596 mGal/km (N-S)\n",
      "[QC] CBA_raw(tgt) plane slope: a=0.4266 mGal/km (E-W), b=-0.1139 mGal/km (N-S)\n",
      "[QC] corr(FAA, bathy)     = nan\n",
      "[QC] corr(FAA, g_corr)    = 0.212\n",
      "[QC] corr(CBA, g_corr)    = -0.967\n",
      "Saved: E:\\wjy\\Gravity\\SCS_Gravity\\out\\Outdata\\CBA_expand_crop\\CBA_raw_expand5.0deg_5.0deg.nc\n",
      "[QC] CBA_raw(tgt) stats: 19.456825256347543 351.2345161437974 200.2684784798807 89.17205981004335\n",
      "Saved: E:\\wjy\\Gravity\\SCS_Gravity\\out\\Outdata\\CBA_expand_crop\\QC_CBA_fullrange.png\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.19",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.19 64-bit ('Netcdf': conda)"
  },
  "interpreter": {
   "hash": "149071d4337f4855c83c48c1185db3f23315ff801e382f6d1e31945d19d1034d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}